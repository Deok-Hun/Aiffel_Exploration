{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPzUDWvtEus8CSbkrOwIyN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deok-Hun/Aiffel_Kun/blob/master/EX_6_%EB%A9%8B%EC%A7%84_%EC%9E%91%EC%82%AC%EA%B0%80_%EB%A7%8C%EB%93%A4%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxToPutm2RWk",
        "outputId": "fe4d7ca4-223e-4e29-de89-0ccd6be83a5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob  #glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다\n",
        "import tensorflow\n",
        "\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GJNXoHB2YEG",
        "outputId": "ac5e4bf3-87fb-4d48-aec2-8723189564ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re"
      ],
      "metadata": {
        "id": "xicPdopc2qqv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HOME\"]=\"\"\n",
        "print(os.getenv(\"HOME\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WZRrHb12tPP",
        "outputId": "4d108da3-86cd-45bb-a3f5-6459d5c5b499"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "iD4Nxj3U4Fbk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 읽어오기"
      ],
      "metadata": {
        "id": "3MsSvUYv4icJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_file_path = os.getenv(\"HOME\")+'/content/drive/MyDrive/Exploration/Exploration_6/data/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "# txt_file_path 경로에 있는 모든 파일명을 리스트 형식으로 txt_list에 할당\n",
        "\n",
        "raw_corpus=[]\n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus에 담는다.\n",
        "for txt_file in txt_list:\n",
        "  with open(txt_file, \"r\") as f:\n",
        "    raw = f.read().splitlines()  # read(): 파일 전체의 내용을 하나의 문자열로 읽어온다.\n",
        "                                 # splitlines(): 여러 라인으로 구분되어 있는 문자열을 한라일씩 분리하여 리스트로 반환\n",
        "    raw_corpus.extend(raw)   # expoend(): 리스트 함수로 추가적인 내용을 연장 한다.\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Exmaples:\\n\" , raw_corpus[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZcuVNxN2zB3",
        "outputId": "cf391dc6-232b-405d-8fbd-14d40bef526f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187088\n",
            "Exmaples:\n",
            " ['Looking for some education', 'Made my way into the night', 'All that bullshit conversation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 정제"
      ],
      "metadata": {
        "id": "YJ_v4tN_4l65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, sentence in enumerate(raw_corpus):\n",
        "  if len(sentence) == 0: continue  # 길이가 0인 문장은 건너 뛴다.\n",
        "  \n",
        "  if idx > 9: break\n",
        "  print(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zoM6jLs386f",
        "outputId": "eaf44664-a970-4db4-97dc-f9df4336f8ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for some education\n",
            "Made my way into the night\n",
            "All that bullshit conversation\n",
            "Baby, can't you read the signs? I won't bore you with the details, baby\n",
            "I don't even wanna waste your time\n",
            "Let's just say that maybe\n",
            "You could help me ease my mind\n",
            "I ain't Mr. Right But if you're looking for fast love\n",
            "If that's love in your eyes\n",
            "It's more than enough\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_sentence(sentence):\n",
        "  sentence = sentence.lower().strip()                   # 1. 소문자 & 양쪽 공백 지우기\n",
        "  sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \",sentence)     # 2. 특수문자 양쪽에 공백 넣기\n",
        "  sentence = re.sub(r'[\" \"]+', \" \", sentence)           # 3. 여러 공백을 하나의 공백으로 바꾸기\n",
        "  sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4. a-zA-Z?.!,¿ 가 아닌 모든 문자를 하나의 공백으로 바꾼다.\n",
        "  sentence = sentence.strip()                           # 5. 다시 양쪽 공백 지우기\n",
        "  sentence = '<start> ' + sentence + ' <end>'           # 6. 문장 시작에는 <start>, 끝에는 <end>를 추가\n",
        "\n",
        "  return sentence\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\")) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kErgwSNU5sG6",
        "outputId": "8fc23028-67fe-43ea-fff6-0537a6c5a9f4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus =[]\n",
        "for sentence in raw_corpus:\n",
        "  if len(sentence) == 0: continue\n",
        "  if sentence[-1] == \":\": continue\n",
        "\n",
        "  preprocessed_sentence = preprocess_sentence(sentence)\n",
        "  corpus.append(preprocessed_sentence)\n",
        "\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2SBebCB-wKo",
        "outputId": "f5b71318-4f7d-4a10-c572-cdc60775ea3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> looking for some education <end>',\n",
              " '<start> made my way into the night <end>',\n",
              " '<start> all that bullshit conversation <end>',\n",
              " '<start> baby , can t you read the signs ? i won t bore you with the details , baby <end>',\n",
              " '<start> i don t even wanna waste your time <end>',\n",
              " '<start> let s just say that maybe <end>',\n",
              " '<start> you could help me ease my mind <end>',\n",
              " '<start> i ain t mr . right but if you re looking for fast love <end>',\n",
              " '<start> if that s love in your eyes <end>',\n",
              " '<start> it s more than enough <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "  # 12,000 단어를 기억할 수 있는 tokenizer를 만든다.\n",
        "  # 여기서는 이미 문장을 정리하여 fiolters가 필요없다.\n",
        "  # 12,000 단어에 포함되지 못한 단어는 '<unk>'로 바꾼다.\n",
        "\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      num_words = 12000,\n",
        "      filters = ' ',\n",
        "      oov_token = '<unk>'\n",
        "  )\n",
        "\n",
        "  tokenizer.fit_on_texts(corpus)  # 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드\n",
        "  tensor = tokenizer.texts_to_sequences(corpus)  # tokenizer를 이용해 corpus를 Tensor로 변환. 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding = 'post') # 입력 데이터의 시퀀스 길이를 일정하게 맞춘다. 패딩을 뒤쪽으로\n",
        "\n",
        "  print(tensor, tokenizer)\n",
        "  return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGjubqUi69Oc",
        "outputId": "2b25076a-6df3-41d4-c610-044c4ffa1497"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2 304  28 ...   0   0   0]\n",
            " [  2 221  13 ...   0   0   0]\n",
            " [  2  24  17 ...   0   0   0]\n",
            " ...\n",
            " [  2  23  77 ...   0   0   0]\n",
            " [  2  42  26 ...   0   0   0]\n",
            " [  2  23  77 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7f7bf7a97a10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in tokenizer.index_word:\n",
        "  print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "  if idx >= 10: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXW24CNN-Quw",
        "outputId": "7db1ea07-cfb6-4f44-c877-eec9e37997ce"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : ,\n",
            "5 : i\n",
            "6 : the\n",
            "7 : you\n",
            "8 : and\n",
            "9 : a\n",
            "10 : to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 제시 조건에 따라 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외\n",
        "\n",
        "src_input = tensor[:,:15]  # tensor에서 마지막 토큰을 잘라서 소스 문장을 생성. 마지막 토큰은 <end>가 아니라 <pad>일 가능성 높다.\n",
        "\n",
        "tgt_input = tensor[:,1:16]   # tensor에서 <start>를 잘라내서 타켓 문장을 생성\n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1Vrgwu2_fqT",
        "outputId": "a2a0cd6f-9319-466e-b0b2-c76bba6fade6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   2  304   28   99 4811    3    0    0    0    0    0    0    0    0\n",
            "    0]\n",
            "[ 304   28   99 4811    3    0    0    0    0    0    0    0    0    0\n",
            "    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 평가 데이터셋 분리"
      ],
      "metadata": {
        "id": "98KH_h5tLZiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,tgt_input, test_size=0.2, random_state=1005)"
      ],
      "metadata": {
        "id": "p_jfuaUVLV4c"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 인공지능 만들기"
      ],
      "metadata": {
        "id": "P7_peISINDOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(enc_train)  # buffer_size 는 보통 전체 데이터의 크기와 같거나 조금 크게 설정\n",
        "BATCH_SIZE = 128\n",
        "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
        "\n",
        "VOCAB_SIZE = tokenizer.num_words + 1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train,dec_train))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder = True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8H2D3ZNADm5",
        "outputId": "71b2629a-4b5e-4688-8ea3-3bf372ec6b6e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(128, 15), dtype=tf.int32, name=None), TensorSpec(shape=(128, 15), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "    super().__init__()\n",
        "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이로 구성\n",
        "    # Embedding 레이어는 단어 산전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
        "    # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다.\n",
        "    # (EX. 만약 embedding_size 가 2라면)\n",
        "    # 차갑다:[0.0, 1.0] / 뜨겁다: [1.0, 0.0], 미지근하다:[0.5, 0.5]\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "    self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "    self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "    self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self,x):\n",
        "    out = self.embedding(x)\n",
        "    out = self.rnn_1(out)\n",
        "    out = self.rnn_2(out)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "# embedding size 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만\n",
        "# 그만큼 충분한 데이터가 없으면 안좋은 결과 값을 가져온다.\n",
        "\n",
        "embedding_size = 512 # 워드 벡터의 차원수를 말하며 단어가 추상적으로 표현되는 크기이다.\n",
        "hidden_size = 2048   # 모델에 얼마나 많은 일꾼을 둘 것인가? 정도로 이해..\n",
        "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size, hidden_size) \n",
        "# tokenizer.num_words 에 +1인 이유는 문장에 없는 pad 가 사용되었기 때문이다."
      ],
      "metadata": {
        "id": "yMUYDiK_M5JI"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋에서 데이터 한 배치만 불러온다\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어둔다.\n",
        "lyricist(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nMqG8b6aZv7",
        "outputId": "c21ec3c1-2536-40bb-a9b9-9c894a5bb6e5"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 15, 12001), dtype=float32, numpy=\n",
              "array([[[-1.3629909e-04,  2.7123376e-04,  3.7818207e-04, ...,\n",
              "          5.8038961e-05,  3.4258395e-04,  7.5319813e-06],\n",
              "        [-3.5436207e-04,  3.9922434e-04,  5.6079961e-04, ...,\n",
              "          1.3399466e-04,  4.8866437e-04,  3.6288882e-04],\n",
              "        [-8.5920835e-04, -3.4527540e-05,  5.8212283e-04, ...,\n",
              "          5.6013133e-04,  7.3939381e-04,  9.7106019e-04],\n",
              "        ...,\n",
              "        [ 5.6735007e-04, -6.8624545e-04, -9.0092374e-04, ...,\n",
              "         -2.7201581e-04,  9.2132341e-06,  2.0301384e-03],\n",
              "        [ 1.1467069e-03, -1.3380365e-03, -1.5325662e-03, ...,\n",
              "         -1.0270918e-04,  2.6411720e-04,  2.0321782e-03],\n",
              "        [ 1.6802745e-03, -1.9834512e-03, -2.1569976e-03, ...,\n",
              "          9.6398646e-05,  5.7963218e-04,  2.0371519e-03]],\n",
              "\n",
              "       [[-1.3629909e-04,  2.7123376e-04,  3.7818207e-04, ...,\n",
              "          5.8038961e-05,  3.4258395e-04,  7.5319813e-06],\n",
              "        [-4.3673474e-05,  4.0245560e-04,  6.1933714e-04, ...,\n",
              "          1.5011622e-04,  9.7734970e-04,  3.5151770e-05],\n",
              "        [ 7.1950693e-05,  5.7559664e-04,  5.2459474e-04, ...,\n",
              "          8.6770066e-05,  1.0160332e-03,  3.4020844e-04],\n",
              "        ...,\n",
              "        [ 6.0255243e-04,  1.8758058e-03,  5.0516363e-04, ...,\n",
              "         -9.1162167e-04,  7.5664237e-04,  9.8633696e-04],\n",
              "        [ 8.0551353e-04,  1.5555782e-03,  5.0436624e-04, ...,\n",
              "         -8.6339889e-04,  5.6142395e-04,  9.8996959e-04],\n",
              "        [ 8.2853605e-04,  1.4628286e-03,  2.3680564e-04, ...,\n",
              "         -9.3837723e-04,  3.3446329e-04,  9.8654872e-04]],\n",
              "\n",
              "       [[-1.3629909e-04,  2.7123376e-04,  3.7818207e-04, ...,\n",
              "          5.8038961e-05,  3.4258395e-04,  7.5319813e-06],\n",
              "        [-6.8533118e-05,  1.1124864e-04,  7.7932520e-04, ...,\n",
              "          3.1782698e-04,  4.3617381e-04,  2.6038632e-04],\n",
              "        [-1.0676710e-04,  2.1876291e-04,  7.6238497e-04, ...,\n",
              "          2.2706531e-04,  4.6173212e-04,  3.7003966e-04],\n",
              "        ...,\n",
              "        [ 3.9004595e-03, -4.5330725e-03, -4.5999489e-03, ...,\n",
              "          1.0081865e-03,  2.4336854e-03,  1.6063291e-03],\n",
              "        [ 4.0901927e-03, -4.7372826e-03, -4.9302420e-03, ...,\n",
              "          1.0523015e-03,  2.6788474e-03,  1.5656060e-03],\n",
              "        [ 4.2514028e-03, -4.8937658e-03, -5.2131079e-03, ...,\n",
              "          1.0747174e-03,  2.9003308e-03,  1.5041900e-03]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.3629909e-04,  2.7123376e-04,  3.7818207e-04, ...,\n",
              "          5.8038961e-05,  3.4258395e-04,  7.5319813e-06],\n",
              "        [-1.3398385e-04,  4.1562412e-04,  3.9565461e-04, ...,\n",
              "         -1.3515998e-04,  8.7765726e-04,  3.6571114e-04],\n",
              "        [ 3.0759716e-04,  8.7307638e-04,  4.1013260e-04, ...,\n",
              "          4.6077712e-05,  1.0507222e-03,  8.3298283e-04],\n",
              "        ...,\n",
              "        [ 2.5280933e-03, -2.1694389e-03, -2.1088889e-03, ...,\n",
              "          6.7345303e-04,  1.0090276e-03,  2.6186507e-03],\n",
              "        [ 2.8131690e-03, -2.7760388e-03, -2.6960319e-03, ...,\n",
              "          7.8611687e-04,  1.2966471e-03,  2.6018410e-03],\n",
              "        [ 3.0669982e-03, -3.3007013e-03, -3.2422990e-03, ...,\n",
              "          8.8795909e-04,  1.6017881e-03,  2.5491866e-03]],\n",
              "\n",
              "       [[-1.3629909e-04,  2.7123376e-04,  3.7818207e-04, ...,\n",
              "          5.8038961e-05,  3.4258395e-04,  7.5319813e-06],\n",
              "        [ 2.8516119e-04,  3.4032657e-04,  3.8583233e-04, ...,\n",
              "          2.0026531e-04,  8.5220527e-04, -7.7386721e-05],\n",
              "        [ 4.0216336e-04,  4.2608171e-04,  2.0444927e-04, ...,\n",
              "          3.3443602e-04,  5.8561238e-04,  2.8364584e-05],\n",
              "        ...,\n",
              "        [ 2.1750371e-03, -1.6996050e-03, -1.2575076e-03, ...,\n",
              "         -5.7831820e-04, -5.1559799e-04,  1.6293302e-03],\n",
              "        [ 2.5550849e-03, -2.2023818e-03, -1.8471261e-03, ...,\n",
              "         -4.2105498e-04, -1.4799158e-04,  1.7665410e-03],\n",
              "        [ 2.9045488e-03, -2.6955844e-03, -2.4236392e-03, ...,\n",
              "         -2.2595354e-04,  2.4973776e-04,  1.8708411e-03]],\n",
              "\n",
              "       [[-1.3629909e-04,  2.7123376e-04,  3.7818207e-04, ...,\n",
              "          5.8038961e-05,  3.4258395e-04,  7.5319813e-06],\n",
              "        [-2.3538589e-04,  6.2860281e-04,  4.7739703e-04, ...,\n",
              "          3.0264421e-04,  1.4828882e-04, -2.9476668e-04],\n",
              "        [-1.9384779e-04,  5.4059405e-04,  5.8202894e-04, ...,\n",
              "          6.8783597e-04,  3.4169134e-04, -2.6098077e-04],\n",
              "        ...,\n",
              "        [ 3.2929941e-03, -3.2314437e-03, -2.1106973e-03, ...,\n",
              "          5.2780908e-04,  1.9154451e-03,  1.5477771e-03],\n",
              "        [ 3.5373501e-03, -3.6815938e-03, -2.7113699e-03, ...,\n",
              "          6.6054426e-04,  2.1656295e-03,  1.6641791e-03],\n",
              "        [ 3.7479284e-03, -4.0600882e-03, -3.2621000e-03, ...,\n",
              "          7.7744777e-04,  2.4105005e-03,  1.7359299e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lyricist.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_0kK67laRax",
        "outputId": "b426f4c0-1520-47b3-ce20-c5f0fc433894"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     multiple                  6144512   \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              multiple                  20979712  \n",
            "                                                                 \n",
            " lstm_17 (LSTM)              multiple                  33562624  \n",
            "                                                                 \n",
            " dense_8 (Dense)             multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,276,897\n",
            "Trainable params: 85,276,897\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam()  # Adam은 현재 가장 많이 사용하는 옵티마이저이다.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits = True,\n",
        "    reduction = 'none'\n",
        ")\n",
        "\n",
        "lyricist.compile(loss=loss, optimizer = optimizer)\n",
        "lyricist.fit(dataset, validation_data=(enc_val, dec_val), epochs=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eow6i2vRaW6P",
        "outputId": "0204bbfb-dfd3-4a8e-d3a6-14820ab3b294"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "1098/1098 [==============================] - 370s 335ms/step - loss: 3.1320 - val_loss: 2.8075\n",
            "Epoch 2/6\n",
            "1098/1098 [==============================] - 371s 338ms/step - loss: 2.5943 - val_loss: 2.5343\n",
            "Epoch 3/6\n",
            "1098/1098 [==============================] - 371s 338ms/step - loss: 2.2163 - val_loss: 2.3576\n",
            "Epoch 4/6\n",
            "1098/1098 [==============================] - 371s 338ms/step - loss: 1.8674 - val_loss: 2.2437\n",
            "Epoch 5/6\n",
            "1098/1098 [==============================] - 409s 373ms/step - loss: 1.5683 - val_loss: 2.1858\n",
            "Epoch 6/6\n",
            "1098/1098 [==============================] - 370s 337ms/step - loss: 1.3331 - val_loss: 2.1688\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b621598d0>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문장생성 함수 정의\n",
        "# 모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
        "\n",
        "def generate_text(lyricist,tokenizer, init_sentence=\"<start>\", max_len = 20): # 시작 문다열을 init_sentence로 받으며 디폴트값은 <start>를 받는다.\n",
        "  # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence]) #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "  # 단어 하나씩 예측해 문장을 만든다.\n",
        "  #   1. 입력받은 문장의 텐서를 입력한다.\n",
        "  #   2. 예측된 값 중 가장 높은 확률인 word index를 뽑아낸다.\n",
        "  #   3. 2에서 예측된 word index를 문장 뒤에 붙인다.\n",
        "  #   4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마친다.(도달하지 못하였으면 while 루프를 돌면서 다음 단어를 예측)\n",
        "  \n",
        "    while True:                # 루프를 돌면서 init_sentence에 단어를 하나씩 생성\n",
        "        # 1\n",
        "        predict = lyricist(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4 \n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated #최종적으로 모델이 생성한 문장을 반환"
      ],
      "metadata": {
        "id": "RucgrjL3bSCq"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\")  # 시작문장으로 i love 를 넣어 문장생성 함수 실행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tIEeHN9R0vNi",
        "outputId": "ba792c61-08a1-463a-9e88-d3a0ec35d448"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you so much <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}